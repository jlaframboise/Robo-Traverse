{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression to Classify Terrain by IMU and Odometry Data from TurtleBot3\n",
    "### By Jacob Laframboise, Jack Demeter\n",
    "Logistic regression works great when the data is randomly split into train and test (high 90 accuracy), but it struggles when the data is split into train/test based on which trial number is was collected in. This further supports the hypothesis that data from each run is more similar to itself than data from a given terrain. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PowerTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "\n",
    "import plotly as ply\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "%matplotlib notebook\n",
    "\n",
    "pd.set_option('display.max_columns', 120)\n",
    "pd.set_option('display.max_rows', 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "We load in individual csv files collected from Rosbag on TurtleBot3 with ROS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set dataFolder path to data file location\n",
    "dataFolder = r\"C:\\Users\\jaker\\Documents\\Experiment3Data-2019-11-21\"\n",
    "\n",
    "dataFiles = [\n",
    "    r\"gMitTile_s15_t8.csv\",\n",
    "    r\"gMitTile_s15_t9.csv\",\n",
    "    r\"gMitTile_s15_t10.csv\",\n",
    "    r\"gTurf_s15_t3.csv\",\n",
    "    r\"gTurf_s15_t4.csv\",\n",
    "    r\"gTurf_s15_t5.csv\",\n",
    "    r\"gTurf_s15_t6.csv\",\n",
    "    r\"gTurf_s15_t7.csv\",\n",
    "    r\"gTurf_s15_t8.csv\",\n",
    "    r\"gTurf_s15_t9.csv\",\n",
    "    r\"gTurf_s15_t10.csv\",\n",
    "    r\"gArcTile_s15_t3.csv\",\n",
    "    r\"gArcTile_s15_t4.csv\",\n",
    "    r\"gArcTile_s15_t5.csv\",\n",
    "    r\"gArcTile_s15_t6.csv\",\n",
    "    r\"gArcTile_s15_t7.csv\",\n",
    "    r\"gArcTile_s15_t8.csv\",\n",
    "    r\"gArcTile_s15_t9.csv\",\n",
    "    r\"gArcTile_s15_t10.csv\",\n",
    "    r\"gCarp_s15_t3.csv\",\n",
    "    r\"gCarp_s15_t4.csv\",\n",
    "    r\"gCarp_s15_t5.csv\",\n",
    "    r\"gCarp_s15_t6.csv\",\n",
    "    r\"gCarp_s15_t7.csv\",\n",
    "    r\"gCarp_s15_t8.csv\",\n",
    "    r\"gCarp_s15_t9.csv\",\n",
    "    r\"gCarp_s15_t10.csv\",\n",
    "    r\"gMitTile_s15_t3.csv\",\n",
    "    r\"gMitTile_s15_t4.csv\",\n",
    "    r\"gMitTile_s15_t5.csv\",\n",
    "    r\"gMitTile_s15_t6.csv\",\n",
    "    r\"gMitTile_s15_t7.csv\"\n",
    "]\n",
    "\n",
    "savePath = \"Data-32Series-Delta30-Squared.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added gMitTile_s15_t8.csv of size (3831, 18) to mainDf. \n",
      "Data series completed: 1/32\n",
      "MainDf is now size (3831, 18)\n",
      "\n",
      "\n",
      "Added gMitTile_s15_t9.csv of size (4331, 18) to mainDf. \n",
      "Data series completed: 2/32\n",
      "MainDf is now size (8162, 18)\n",
      "\n",
      "\n",
      "Added gMitTile_s15_t10.csv of size (4853, 18) to mainDf. \n",
      "Data series completed: 3/32\n",
      "MainDf is now size (13015, 18)\n",
      "\n",
      "\n",
      "Added gTurf_s15_t3.csv of size (6101, 18) to mainDf. \n",
      "Data series completed: 4/32\n",
      "MainDf is now size (19116, 18)\n",
      "\n",
      "\n",
      "Added gTurf_s15_t4.csv of size (5840, 18) to mainDf. \n",
      "Data series completed: 5/32\n",
      "MainDf is now size (24956, 18)\n",
      "\n",
      "\n",
      "Added gTurf_s15_t5.csv of size (3352, 18) to mainDf. \n",
      "Data series completed: 6/32\n",
      "MainDf is now size (28308, 18)\n",
      "\n",
      "\n",
      "Added gTurf_s15_t6.csv of size (5253, 18) to mainDf. \n",
      "Data series completed: 7/32\n",
      "MainDf is now size (33561, 18)\n",
      "\n",
      "\n",
      "Added gTurf_s15_t7.csv of size (5251, 18) to mainDf. \n",
      "Data series completed: 8/32\n",
      "MainDf is now size (38812, 18)\n",
      "\n",
      "\n",
      "Added gTurf_s15_t8.csv of size (6668, 18) to mainDf. \n",
      "Data series completed: 9/32\n",
      "MainDf is now size (45480, 18)\n",
      "\n",
      "\n",
      "Added gTurf_s15_t9.csv of size (5075, 18) to mainDf. \n",
      "Data series completed: 10/32\n",
      "MainDf is now size (50555, 18)\n",
      "\n",
      "\n",
      "Added gTurf_s15_t10.csv of size (7149, 18) to mainDf. \n",
      "Data series completed: 11/32\n",
      "MainDf is now size (57704, 18)\n",
      "\n",
      "\n",
      "Added gArcTile_s15_t3.csv of size (6218, 18) to mainDf. \n",
      "Data series completed: 12/32\n",
      "MainDf is now size (63922, 18)\n",
      "\n",
      "\n",
      "Added gArcTile_s15_t4.csv of size (4618, 18) to mainDf. \n",
      "Data series completed: 13/32\n",
      "MainDf is now size (68540, 18)\n",
      "\n",
      "\n",
      "Added gArcTile_s15_t5.csv of size (5554, 18) to mainDf. \n",
      "Data series completed: 14/32\n",
      "MainDf is now size (74094, 18)\n",
      "\n",
      "\n",
      "Added gArcTile_s15_t6.csv of size (4747, 18) to mainDf. \n",
      "Data series completed: 15/32\n",
      "MainDf is now size (78841, 18)\n",
      "\n",
      "\n",
      "Added gArcTile_s15_t7.csv of size (4021, 18) to mainDf. \n",
      "Data series completed: 16/32\n",
      "MainDf is now size (82862, 18)\n",
      "\n",
      "\n",
      "Added gArcTile_s15_t8.csv of size (3641, 18) to mainDf. \n",
      "Data series completed: 17/32\n",
      "MainDf is now size (86503, 18)\n",
      "\n",
      "\n",
      "Added gArcTile_s15_t9.csv of size (6431, 18) to mainDf. \n",
      "Data series completed: 18/32\n",
      "MainDf is now size (92934, 18)\n",
      "\n",
      "\n",
      "Added gArcTile_s15_t10.csv of size (4441, 18) to mainDf. \n",
      "Data series completed: 19/32\n",
      "MainDf is now size (97375, 18)\n",
      "\n",
      "\n",
      "Added gCarp_s15_t3.csv of size (2534, 18) to mainDf. \n",
      "Data series completed: 20/32\n",
      "MainDf is now size (99909, 18)\n",
      "\n",
      "\n",
      "Added gCarp_s15_t4.csv of size (3028, 18) to mainDf. \n",
      "Data series completed: 21/32\n",
      "MainDf is now size (102937, 18)\n",
      "\n",
      "\n",
      "Added gCarp_s15_t5.csv of size (2820, 18) to mainDf. \n",
      "Data series completed: 22/32\n",
      "MainDf is now size (105757, 18)\n",
      "\n",
      "\n",
      "Added gCarp_s15_t6.csv of size (4819, 18) to mainDf. \n",
      "Data series completed: 23/32\n",
      "MainDf is now size (110576, 18)\n",
      "\n",
      "\n",
      "Added gCarp_s15_t7.csv of size (2492, 18) to mainDf. \n",
      "Data series completed: 24/32\n",
      "MainDf is now size (113068, 18)\n",
      "\n",
      "\n",
      "Added gCarp_s15_t8.csv of size (5633, 18) to mainDf. \n",
      "Data series completed: 25/32\n",
      "MainDf is now size (118701, 18)\n",
      "\n",
      "\n",
      "Added gCarp_s15_t9.csv of size (6742, 18) to mainDf. \n",
      "Data series completed: 26/32\n",
      "MainDf is now size (125443, 18)\n",
      "\n",
      "\n",
      "Added gCarp_s15_t10.csv of size (6740, 18) to mainDf. \n",
      "Data series completed: 27/32\n",
      "MainDf is now size (132183, 18)\n",
      "\n",
      "\n",
      "Added gMitTile_s15_t3.csv of size (5307, 18) to mainDf. \n",
      "Data series completed: 28/32\n",
      "MainDf is now size (137490, 18)\n",
      "\n",
      "\n",
      "Added gMitTile_s15_t4.csv of size (4724, 18) to mainDf. \n",
      "Data series completed: 29/32\n",
      "MainDf is now size (142214, 18)\n",
      "\n",
      "\n",
      "Added gMitTile_s15_t5.csv of size (3879, 18) to mainDf. \n",
      "Data series completed: 30/32\n",
      "MainDf is now size (146093, 18)\n",
      "\n",
      "\n",
      "Added gMitTile_s15_t6.csv of size (4708, 18) to mainDf. \n",
      "Data series completed: 31/32\n",
      "MainDf is now size (150801, 18)\n",
      "\n",
      "\n",
      "Added gMitTile_s15_t7.csv of size (4184, 18) to mainDf. \n",
      "Data series completed: 32/32\n",
      "MainDf is now size (154985, 18)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "For each data file we:\n",
    "adjust the index, \n",
    "interpolate NaN values,\n",
    "drop remaining NaN values, \n",
    "drop some empty columns.\n",
    "\n",
    "We then augment the feature space with delta columns, \n",
    "and with polynomial columns,\n",
    "and label the columns with terrain, speed, and trial number\n",
    "\"\"\"\n",
    "for i in range(len(dataFiles)):\n",
    "    # get speed/terrain based on file name\n",
    "    terrain = dataFiles[i].split('_')[0][1:]\n",
    "    speed = dataFiles[i].split('_s')[1][:2]\n",
    "    trial = dataFiles[i].split('_t')[1][0]\n",
    "\n",
    "    df = pd.read_csv(os.path.join(dataFolder, dataFiles[i]))\n",
    "    df = df.rename(columns={'Unnamed: 0': 'Seq'})\n",
    "    df = df.set_index('Seq')\n",
    "\n",
    "    # interpolate the missing data with a polynomial (upscaling)\n",
    "    df = df.interpolate(method='polynomial', order=1)\n",
    "\n",
    "    # remove incomplete entries\n",
    "    df = df.dropna()\n",
    "\n",
    "    # reset data to be ordered based on Sequence\n",
    "    df = df.reset_index().drop(columns=['Seq'])\n",
    "\n",
    "    \n",
    "    df = df.drop(columns=['OdomPosZ', 'OdomOrientX', 'OdomOrientY', 'OdomLinY', 'OdomLinZ', 'OdomAngX', 'OdomAngY'])\n",
    "    # use the XY magnitude to remove unique run IDs\n",
    "    df['OdomPosXY'] = np.sqrt(df.OdomPosX**2 + df.OdomPosY**2)\n",
    "    df = df.drop(columns=['OdomPosY', 'OdomPosX'])\n",
    "    \n",
    "    # Order is the exponent applied to the delta data sets to allow LR to find higher polynomial patterns, increases memory and comp. time\n",
    "    order=2\n",
    "    # the delta list specifies how many data points to go back to and apply the \n",
    "    dList = range(1, 302, 20)\n",
    "    for col in df.columns.tolist():\n",
    "        if col!='Sensor':\n",
    "            for d in dList:\n",
    "                df[col+'Delta{}'.format(d)] = df[col].diff(d)\n",
    "                if order>1:\n",
    "                    for p in range(2, order+1):\n",
    "                        df[col+'Delta{}Exp{}'.format(d, p)] = df[col+'Delta{}'.format(d)]**p\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    df = df.reset_index().drop(columns=['index'])\n",
    "    df = df.drop(columns=['Sensor', 'Time'])\n",
    "    df['Speed']=int(speed)\n",
    "    df['Terrain']=terrain\n",
    "    df['Trial']=int(trial)\n",
    "\n",
    "    if i==0:\n",
    "        mainDf = df.copy(deep=True)\n",
    "    else:\n",
    "        mainDf = pd.concat([mainDf, df], axis=0, sort=False)\n",
    "print(\"Data series completed.\")\n",
    "print(\"MainDf is now size {}\".format(mainDf.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid reloading dataset when working, removing this can reduce memory usage (doubles)\n",
    "df = mainDf.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OdomOrientZ</th>\n",
       "      <th>OdomOrientW</th>\n",
       "      <th>OdomLinX</th>\n",
       "      <th>OdomAngZ</th>\n",
       "      <th>ImuOrientX</th>\n",
       "      <th>ImuOrientY</th>\n",
       "      <th>ImuOrientZ</th>\n",
       "      <th>ImuOrientW</th>\n",
       "      <th>ImuAngVelX</th>\n",
       "      <th>ImuAngVelY</th>\n",
       "      <th>ImuAngVelZ</th>\n",
       "      <th>ImuAccelX</th>\n",
       "      <th>ImuAccelY</th>\n",
       "      <th>ImuAccelZ</th>\n",
       "      <th>OdomPosXY</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Terrain</th>\n",
       "      <th>Trial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.093628</td>\n",
       "      <td>0.995607</td>\n",
       "      <td>0.149563</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>-0.012936</td>\n",
       "      <td>0.003677</td>\n",
       "      <td>-0.102512</td>\n",
       "      <td>-0.994637</td>\n",
       "      <td>0.014367</td>\n",
       "      <td>-0.002661</td>\n",
       "      <td>0.006917</td>\n",
       "      <td>0.521337</td>\n",
       "      <td>0.494403</td>\n",
       "      <td>10.553940</td>\n",
       "      <td>18.812442</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.093710</td>\n",
       "      <td>0.995599</td>\n",
       "      <td>0.149276</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>-0.013177</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>-0.102530</td>\n",
       "      <td>-0.994631</td>\n",
       "      <td>0.019156</td>\n",
       "      <td>0.017027</td>\n",
       "      <td>0.008514</td>\n",
       "      <td>0.788291</td>\n",
       "      <td>0.634463</td>\n",
       "      <td>9.111135</td>\n",
       "      <td>18.812380</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.093793</td>\n",
       "      <td>0.995592</td>\n",
       "      <td>0.148988</td>\n",
       "      <td>0.008748</td>\n",
       "      <td>-0.013698</td>\n",
       "      <td>0.004072</td>\n",
       "      <td>-0.102570</td>\n",
       "      <td>-0.994619</td>\n",
       "      <td>0.020220</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>0.014899</td>\n",
       "      <td>0.219069</td>\n",
       "      <td>0.453701</td>\n",
       "      <td>10.493187</td>\n",
       "      <td>18.812318</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.093875</td>\n",
       "      <td>0.995584</td>\n",
       "      <td>0.148700</td>\n",
       "      <td>0.012429</td>\n",
       "      <td>-0.012621</td>\n",
       "      <td>0.002504</td>\n",
       "      <td>-0.102654</td>\n",
       "      <td>-0.994628</td>\n",
       "      <td>0.015431</td>\n",
       "      <td>0.030330</td>\n",
       "      <td>0.012770</td>\n",
       "      <td>-0.061052</td>\n",
       "      <td>0.196325</td>\n",
       "      <td>10.284293</td>\n",
       "      <td>18.812256</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.093843</td>\n",
       "      <td>0.995587</td>\n",
       "      <td>0.148514</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>-0.011543</td>\n",
       "      <td>0.000936</td>\n",
       "      <td>-0.102737</td>\n",
       "      <td>-0.994637</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>0.034054</td>\n",
       "      <td>0.010642</td>\n",
       "      <td>-0.341174</td>\n",
       "      <td>-0.061052</td>\n",
       "      <td>10.075399</td>\n",
       "      <td>18.812234</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.093811</td>\n",
       "      <td>0.995590</td>\n",
       "      <td>0.148328</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>-0.011305</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>-0.102711</td>\n",
       "      <td>-0.994643</td>\n",
       "      <td>-0.009578</td>\n",
       "      <td>0.015963</td>\n",
       "      <td>-0.008514</td>\n",
       "      <td>-0.915184</td>\n",
       "      <td>-0.056264</td>\n",
       "      <td>10.979809</td>\n",
       "      <td>18.812212</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.093779</td>\n",
       "      <td>0.995593</td>\n",
       "      <td>0.148142</td>\n",
       "      <td>0.001390</td>\n",
       "      <td>-0.011305</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>-0.102711</td>\n",
       "      <td>-0.994643</td>\n",
       "      <td>-0.009578</td>\n",
       "      <td>0.015963</td>\n",
       "      <td>-0.008514</td>\n",
       "      <td>-0.915184</td>\n",
       "      <td>-0.056264</td>\n",
       "      <td>10.979809</td>\n",
       "      <td>18.812190</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.093746</td>\n",
       "      <td>0.995596</td>\n",
       "      <td>0.147956</td>\n",
       "      <td>-0.002290</td>\n",
       "      <td>-0.011117</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>-0.102601</td>\n",
       "      <td>-0.994656</td>\n",
       "      <td>-0.007449</td>\n",
       "      <td>-0.004257</td>\n",
       "      <td>-0.028733</td>\n",
       "      <td>-1.149217</td>\n",
       "      <td>0.062848</td>\n",
       "      <td>9.466673</td>\n",
       "      <td>18.812168</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.093714</td>\n",
       "      <td>0.995599</td>\n",
       "      <td>0.147770</td>\n",
       "      <td>-0.005970</td>\n",
       "      <td>-0.011083</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>-0.102489</td>\n",
       "      <td>-0.994668</td>\n",
       "      <td>0.009578</td>\n",
       "      <td>-0.037247</td>\n",
       "      <td>-0.028733</td>\n",
       "      <td>-0.572214</td>\n",
       "      <td>0.187945</td>\n",
       "      <td>8.793902</td>\n",
       "      <td>18.812146</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.093682</td>\n",
       "      <td>0.995602</td>\n",
       "      <td>0.147584</td>\n",
       "      <td>-0.009650</td>\n",
       "      <td>-0.010887</td>\n",
       "      <td>-0.000046</td>\n",
       "      <td>-0.102468</td>\n",
       "      <td>-0.994672</td>\n",
       "      <td>0.026605</td>\n",
       "      <td>-0.045761</td>\n",
       "      <td>-0.007449</td>\n",
       "      <td>0.708085</td>\n",
       "      <td>-0.201113</td>\n",
       "      <td>10.211270</td>\n",
       "      <td>18.812124</td>\n",
       "      <td>15</td>\n",
       "      <td>MitTile</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OdomOrientZ  OdomOrientW  OdomLinX  OdomAngZ  ImuOrientX  ImuOrientY  \\\n",
       "0     0.093628     0.995607  0.149563  0.001384   -0.012936    0.003677   \n",
       "1     0.093710     0.995599  0.149276  0.005066   -0.013177    0.003931   \n",
       "2     0.093793     0.995592  0.148988  0.008748   -0.013698    0.004072   \n",
       "3     0.093875     0.995584  0.148700  0.012429   -0.012621    0.002504   \n",
       "4     0.093843     0.995587  0.148514  0.008750   -0.011543    0.000936   \n",
       "5     0.093811     0.995590  0.148328  0.005070   -0.011305    0.000417   \n",
       "6     0.093779     0.995593  0.148142  0.001390   -0.011305    0.000417   \n",
       "7     0.093746     0.995596  0.147956 -0.002290   -0.011117   -0.000264   \n",
       "8     0.093714     0.995599  0.147770 -0.005970   -0.011083   -0.000845   \n",
       "9     0.093682     0.995602  0.147584 -0.009650   -0.010887   -0.000046   \n",
       "\n",
       "   ImuOrientZ  ImuOrientW  ImuAngVelX  ImuAngVelY  ImuAngVelZ  ImuAccelX  \\\n",
       "0   -0.102512   -0.994637    0.014367   -0.002661    0.006917   0.521337   \n",
       "1   -0.102530   -0.994631    0.019156    0.017027    0.008514   0.788291   \n",
       "2   -0.102570   -0.994619    0.020220    0.026605    0.014899   0.219069   \n",
       "3   -0.102654   -0.994628    0.015431    0.030330    0.012770  -0.061052   \n",
       "4   -0.102737   -0.994637    0.010642    0.034054    0.010642  -0.341174   \n",
       "5   -0.102711   -0.994643   -0.009578    0.015963   -0.008514  -0.915184   \n",
       "6   -0.102711   -0.994643   -0.009578    0.015963   -0.008514  -0.915184   \n",
       "7   -0.102601   -0.994656   -0.007449   -0.004257   -0.028733  -1.149217   \n",
       "8   -0.102489   -0.994668    0.009578   -0.037247   -0.028733  -0.572214   \n",
       "9   -0.102468   -0.994672    0.026605   -0.045761   -0.007449   0.708085   \n",
       "\n",
       "   ImuAccelY  ImuAccelZ  OdomPosXY  Speed  Terrain  Trial  \n",
       "0   0.494403  10.553940  18.812442     15  MitTile      8  \n",
       "1   0.634463   9.111135  18.812380     15  MitTile      8  \n",
       "2   0.453701  10.493187  18.812318     15  MitTile      8  \n",
       "3   0.196325  10.284293  18.812256     15  MitTile      8  \n",
       "4  -0.061052  10.075399  18.812234     15  MitTile      8  \n",
       "5  -0.056264  10.979809  18.812212     15  MitTile      8  \n",
       "6  -0.056264  10.979809  18.812190     15  MitTile      8  \n",
       "7   0.062848   9.466673  18.812168     15  MitTile      8  \n",
       "8   0.187945   8.793902  18.812146     15  MitTile      8  \n",
       "9  -0.201113  10.211270  18.812124     15  MitTile      8  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sample output of the data\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(145353, 1506)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for none values and correct size\n",
    "print(df.isnull().sum().sum()) # check for NaN\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering: elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate features that may ID individual runs improperly\n",
    "# only retain delta data, speed, and terrain(the label)\n",
    "columnsToDrop = [x for x in df.columns.tolist() if 'Time' in x or ('Delta' not in x and 'Speed' not in x and 'Terrain' not in x and 'Trial' not in x) ]\n",
    "df = df.drop(columns=columnsToDrop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group carp/turf and Tiles into 2 broader categories to attempt differentiation of similar terrains\n",
    "df['Terrain'] = df['Terrain'].replace({'Carp':'Turf', 'ArcTile':'MitTile'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speed filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Speed']==15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "Now that we have processed the data, we can apply logistic regression to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the train test split where train on t1 test on t2\n",
    "dfTrain = df[df['Trial']<9]\n",
    "dfTest = df[df['Trial']>=9]\n",
    "\n",
    "Y_train = dfTrain['Terrain']\n",
    "Y_test = dfTest['Terrain']\n",
    "\n",
    "X_train = dfTrain.drop(columns=['Terrain', 'Speed', 'Trial'])\n",
    "X_test = dfTest.drop(columns=['Terrain', 'Speed', 'Trial'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature engineering: Kbest features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImuAngVelXDelta21Exp2\n"
     ]
    }
   ],
   "source": [
    "# highlight and utilize only the Kbest features in an attempt to reduce computation speed\n",
    "featureCount = 30\n",
    "test = SelectKBest(k=featureCount)\n",
    "fit = test.fit(X_train, Y_train)\n",
    "\n",
    "print(X_test.columns.tolist()[fit.scores_.argmax()])\n",
    "\n",
    "# fit testing data\n",
    "X_train = fit.transform(X_train)\n",
    "X_test = fit.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(123978, 30)\n",
      "(123978,)\n",
      "(21375, 30)\n",
      "(21375,)\n"
     ]
    }
   ],
   "source": [
    "# check proper sizing\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model running and accuracy exploration\n",
    "During our testing an accuracy of approx. 73.37% was found when the data was split into two catergories, given that random guesses would result in ~50% accuracy the model did succeed, however not enough for the team to explore the additional applications that were initially intended for the data. Exploration with NN and other methods provided similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jaker\\Anaconda3\\envs\\tf-p37\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning:\n",
      "\n",
      "Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver = \"lbfgs\")\n",
    "model.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test set is: 0.7336608187134503\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy on test set is: {}\".format(model.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
